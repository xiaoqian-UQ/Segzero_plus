data:
  train_files: Ricky06662/refCOCOg_9k_840
  val_files: None
  prompt_key: prompt
  image_key: image
  max_prompt_length: 2048
  max_response_length: 512
  rollout_batch_size: 32
  shuffle: true
  seed: 42
  max_pixels: 12845056
  min_pixels: 3136

algorithm:
  adv_estimator: grpo
  norm_adv_by_std_in_grpo: true
  kl_coef: 0.0

worker:
  actor:
    global_batch_size: 32
    micro_batch_size_per_device_for_update: 1
    micro_batch_size_per_device_for_experience: 1
    max_grad_norm: 1.0
    use_kl_loss: true
    kl_loss_coef: 5.0e-3
    kl_loss_type: low_var_kl
    model:
      model_path: /mnt/xiaoqian/model/pretrained_models/Seg-Zero-7B/
      enable_gradient_checkpointing: true
    optim:
      lr: 1.0e-6
      weight_decay: 1.0e-2
    fsdp:
      param_offload: false
      optimizer_offload: false
      torch_dtype: bf16
    offload:
      param_offload: false
      optimizer_offload: false

  rollout:
    temperature: 1.0
    top_p: 1.0
    tensor_parallel_size: 2
    gpu_memory_utilization: 0.88
    n: 4
    enable_chunked_prefill: true

  ref:
    fsdp:
      torch_dtype: bf16
    offload:
      param_offload: false

  reward:
    reward_type: function
    compute_score: seg_strict

trainer:
  total_training_steps: 300
  save_freq: 50
  val_freq: 25
  log_freq: 10
  logger: ["console", "wandb"]
  project_name: segzero-plus
  experiment_name: segzero_plus_neg_points_2xa6000
  n_gpus_per_node: 2
  nnodes: 1
  val_before_train: false
  val_only: false

custom:
  use_negative_reward: true
  negative_reward_weight: 1.0
  use_confused_regions: true
  confused_regions_dir: ""
  negative_alpha: 1.0
  negative_beta: 0.5
  max_negative_points: 2
  use_strict_format: true
  prompt_template: negative_point
  sam_model_path: /mnt/xiaoqian/model/sam2/checkpoints/sam2.1_hiera_large.pt
  image_size: 840
